# PPO-Algorithm

<p>I implemented three versions of the PPO-Algorithm:</p>

<ul>
	<li> Usual PPO as in ..., color: red </li>
	<li> PPO with clipped objective as in ... in bright blue </li>
	<li> PPO with adaptive Kullback-Leibler Divergence as in ... in dark blue </li>
</ul>


We test these three versions on the 'CartPole-v1'environment.

Train:
![alt text](https://github.com/alexbaumi/PPO-Algorithm/blob/main/figures/TrainReward.svg?raw=true)
Test:
![alt text](https://github.com/alexbaumi/PPO-Algorithm/blob/main/figures/TestReward.svg?raw=true)
  
